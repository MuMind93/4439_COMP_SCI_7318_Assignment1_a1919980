{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuMind93/4439_COMP_SCI_7318_Assignment1_a1919980/blob/main/new_recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0786bae9-1c80-471d-8344-b0827c3f70ba",
      "metadata": {
        "id": "0786bae9-1c80-471d-8344-b0827c3f70ba"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2h-vwHrEtEn",
        "outputId": "4b79e85c-5801-4e44-cd2f-1f2bd59521ec"
      },
      "id": "X2h-vwHrEtEn",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_scatter-2.1.2%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu117\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_sparse-0.6.18%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu117\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "dbd42f65-dd62-41dd-8c7d-7af0586345bf",
      "metadata": {
        "id": "dbd42f65-dd62-41dd-8c7d-7af0586345bf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import HeteroConv, SAGEConv\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b269e83-a913-4fec-bc54-8b038ff84203",
      "metadata": {
        "id": "8b269e83-a913-4fec-bc54-8b038ff84203"
      },
      "source": [
        "## 2. Load and Merge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a463ab5f-fd27-4594-b9fd-b3db217b543f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a463ab5f-fd27-4594-b9fd-b3db217b543f",
        "outputId": "b2d1126d-0bda-460d-ae26-a8c5f1c77589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Data:\n",
            "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
            "0   1187899        1    train            11          4                  8   \n",
            "1   1187899        1    train            11          4                  8   \n",
            "2   1187899        1    train            11          4                  8   \n",
            "3   1187899        1    train            11          4                  8   \n",
            "4   1187899        1    train            11          4                  8   \n",
            "\n",
            "   days_since_prior_order  product_id  add_to_cart_order  reordered  \\\n",
            "0                    14.0         196                  1          1   \n",
            "1                    14.0       25133                  2          1   \n",
            "2                    14.0       38928                  3          1   \n",
            "3                    14.0       26405                  4          1   \n",
            "4                    14.0       39657                  5          1   \n",
            "\n",
            "                       product_name  aisle_id  department_id  \n",
            "0                              Soda        77              7  \n",
            "1             Organic String Cheese        21             16  \n",
            "2          0% Greek Strained Yogurt       120             16  \n",
            "3  XL Pick-A-Size Paper Towel Rolls        54             17  \n",
            "4            Milk Chocolate Almonds        45             19  \n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "aisles = pd.read_csv(\"aisles.csv\")\n",
        "departments = pd.read_csv(\"departments.csv\")\n",
        "order_products_prior = pd.read_csv(\"order_products__train.csv\")\n",
        "orders = pd.read_csv(\"orders.csv\")\n",
        "products = pd.read_csv(\"products.csv\")\n",
        "\n",
        "# Merge orders with order_products_prior\n",
        "merged_data = orders.merge(order_products_prior, on=\"order_id\", how=\"inner\")\n",
        "\n",
        "# Merge with products to include product details\n",
        "merged_data = merged_data.merge(products, on=\"product_id\", how=\"inner\")\n",
        "\n",
        "# Display merged data for verification\n",
        "print(\"Merged Data:\")\n",
        "print(merged_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8475c8-4427-4eed-b271-c6c368b1f333",
      "metadata": {
        "id": "ce8475c8-4427-4eed-b271-c6c368b1f333"
      },
      "source": [
        "## 3. Prepare User Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "73ed6962-4c1b-48a0-9b58-6e6dae6d4911",
      "metadata": {
        "scrolled": true,
        "id": "73ed6962-4c1b-48a0-9b58-6e6dae6d4911"
      },
      "outputs": [],
      "source": [
        "# Map user_id and product_id to unique indices\n",
        "unique_users = merged_data[\"user_id\"].unique()\n",
        "unique_products = merged_data[\"product_id\"].unique()\n",
        "\n",
        "user_mapping = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
        "product_mapping = {product_id: idx for idx, product_id in enumerate(unique_products)}\n",
        "\n",
        "# Map IDs in the merged data\n",
        "merged_data[\"user_idx\"] = merged_data[\"user_id\"].map(user_mapping)\n",
        "merged_data[\"product_idx\"] = merged_data[\"product_id\"].map(product_mapping)\n",
        "\n",
        "# Create user features\n",
        "user_features = pd.DataFrame({\n",
        "    \"user_id\": unique_users,\n",
        "    \"total_orders\": orders.groupby(\"user_id\").size().reindex(unique_users).fillna(0).values,\n",
        "})\n",
        "user_features[\"avg_days_between_orders\"] = orders.groupby(\"user_id\")[\"days_since_prior_order\"].mean().reindex(unique_users).fillna(0).values\n",
        "user_features[\"weekend_order_ratio\"] = orders.groupby(\"user_id\")[\"order_dow\"].apply(\n",
        "    lambda x: (x >= 5).sum() / len(x)\n",
        ").reindex(unique_users).fillna(0).values\n",
        "\n",
        "# Convert to tensor\n",
        "user_features_tensor = torch.tensor(\n",
        "    user_features.drop(columns=[\"user_id\"]).values, dtype=torch.float\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcf8649-fa84-414a-9de1-466e597222df",
      "metadata": {
        "id": "3fcf8649-fa84-414a-9de1-466e597222df"
      },
      "source": [
        "## 4. Prepare Product Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b04f5e1-8744-47ad-9c9c-83cd32a13a12",
      "metadata": {
        "id": "6b04f5e1-8744-47ad-9c9c-83cd32a13a12"
      },
      "outputs": [],
      "source": [
        "# Create product features\n",
        "product_features = pd.DataFrame({\n",
        "    \"product_id\": unique_products,\n",
        "    \"total_purchases\": merged_data.groupby(\"product_id\").size().values,\n",
        "    \"avg_cart_position\": merged_data.groupby(\"product_id\")[\"add_to_cart_order\"].mean().values,\n",
        "    \"reorder_rate\": merged_data.groupby(\"product_id\")[\"reordered\"].mean().values,\n",
        "})\n",
        "\n",
        "# Convert to tensor\n",
        "product_features_tensor = torch.tensor(\n",
        "    product_features.drop(columns=[\"product_id\"]).values, dtype=torch.float\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da8d570f-cdc3-4789-b51e-13e07bee2c8b",
      "metadata": {
        "id": "da8d570f-cdc3-4789-b51e-13e07bee2c8b"
      },
      "source": [
        "## 5. Prepare Edge Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cd3d2476-a0d1-441a-875d-9418fa01e2a8",
      "metadata": {
        "id": "cd3d2476-a0d1-441a-875d-9418fa01e2a8"
      },
      "outputs": [],
      "source": [
        "# Create edge features for user-product interactions\n",
        "user_product_features = merged_data.groupby([\"user_idx\", \"product_idx\"]).agg({\n",
        "    \"add_to_cart_order\": \"mean\",\n",
        "    \"days_since_prior_order\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "# Prepare edge index\n",
        "edge_index = torch.tensor(\n",
        "    user_product_features[[\"user_idx\", \"product_idx\"]].values.T, dtype=torch.long\n",
        ")\n",
        "\n",
        "# Prepare edge features\n",
        "edge_features_tensor = torch.tensor(\n",
        "    user_product_features[[\"add_to_cart_order\", \"days_since_prior_order\"]].values,\n",
        "    dtype=torch.float\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd8aa38b-dcf7-47a1-b303-257dcdf8eb8a",
      "metadata": {
        "id": "fd8aa38b-dcf7-47a1-b303-257dcdf8eb8a"
      },
      "source": [
        "## 6. Create Heterogeneous Data Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4d3d181b-c21a-44e0-823e-1544f1350525",
      "metadata": {
        "id": "4d3d181b-c21a-44e0-823e-1544f1350525"
      },
      "outputs": [],
      "source": [
        "# Create Heterogeneous Data object\n",
        "data = HeteroData()\n",
        "data['user'].x = user_features_tensor  # User node features\n",
        "data['product'].x = product_features_tensor  # Product node features\n",
        "data['user', 'bought', 'product'].edge_index = edge_index  # Edge index\n",
        "data['user', 'bought', 'product'].edge_attr = edge_features_tensor  # Edge features\n",
        "# Add reverse edges ('product', 'bought_by', 'user')\n",
        "data['product', 'bought_by', 'user'].edge_index = edge_index[[1, 0]]  # Reverse the edge index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df5e416b-8666-456e-8468-57dc7a86cec8",
      "metadata": {
        "id": "df5e416b-8666-456e-8468-57dc7a86cec8"
      },
      "source": [
        "## 7. Split Data into Train, Validation, and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8f392d2a-de07-4bb1-a7c8-fe8173bcd6bc",
      "metadata": {
        "id": "8f392d2a-de07-4bb1-a7c8-fe8173bcd6bc"
      },
      "outputs": [],
      "source": [
        "# Convert edge index and edge attributes to NumPy arrays\n",
        "edges = data['user', 'bought', 'product'].edge_index.numpy().T\n",
        "edge_attrs = data['user', 'bought', 'product'].edge_attr.numpy()\n",
        "\n",
        "# Split edges into training, validation, and test sets\n",
        "train_edges, val_test_edges, train_attrs, val_test_attrs = train_test_split(\n",
        "    edges, edge_attrs, test_size=0.3, random_state=42\n",
        ")\n",
        "val_edges, test_edges, val_attrs, test_attrs = train_test_split(\n",
        "    val_test_edges, val_test_attrs, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Create separate data objects for train, validation, and test\n",
        "train_data = HeteroData()\n",
        "train_data['user'].x = data['user'].x\n",
        "train_data['product'].x = data['product'].x\n",
        "train_data['user', 'bought', 'product'].edge_index = torch.tensor(train_edges.T, dtype=torch.long)\n",
        "train_data['user', 'bought', 'product'].edge_attr = torch.tensor(train_attrs, dtype=torch.float)\n",
        "\n",
        "val_data = HeteroData()\n",
        "val_data['user'].x = data['user'].x\n",
        "val_data['product'].x = data['product'].x\n",
        "val_data['user', 'bought', 'product'].edge_index = torch.tensor(val_edges.T, dtype=torch.long)\n",
        "val_data['user', 'bought', 'product'].edge_attr = torch.tensor(val_attrs, dtype=torch.float)\n",
        "\n",
        "test_data = HeteroData()\n",
        "test_data['user'].x = data['user'].x\n",
        "test_data['product'].x = data['product'].x\n",
        "test_data['user', 'bought', 'product'].edge_index = torch.tensor(test_edges.T, dtype=torch.long)\n",
        "test_data['user', 'bought', 'product'].edge_attr = torch.tensor(test_attrs, dtype=torch.float)\n",
        "\n",
        "# Add reverse edges to train, validation, and test data\n",
        "train_data['product', 'bought_by', 'user'].edge_index = train_data['user', 'bought', 'product'].edge_index[[1, 0]]\n",
        "val_data['product', 'bought_by', 'user'].edge_index = val_data['user', 'bought', 'product'].edge_index[[1, 0]]\n",
        "test_data['product', 'bought_by', 'user'].edge_index = test_data['user', 'bought', 'product'].edge_index[[1, 0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f79b843-49e7-48f9-a811-1f9c7bd23106",
      "metadata": {
        "id": "9f79b843-49e7-48f9-a811-1f9c7bd23106"
      },
      "source": [
        "## 8. Define the Heterogeneous GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f8acfa55-184e-4db4-8e35-3a4796a4e6cd",
      "metadata": {
        "id": "f8acfa55-184e-4db4-8e35-3a4796a4e6cd"
      },
      "outputs": [],
      "source": [
        "class HeteroGNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, output_dim):\n",
        "        super(HeteroGNN, self).__init__()\n",
        "        self.conv1 = HeteroConv({\n",
        "            ('user', 'bought', 'product'): SAGEConv((-1, -1), hidden_dim),\n",
        "            ('product', 'bought_by', 'user'): SAGEConv((-1, -1), hidden_dim),\n",
        "        }, aggr='mean')\n",
        "        self.conv2 = HeteroConv({\n",
        "            ('user', 'bought', 'product'): SAGEConv((-1, -1), output_dim),\n",
        "            ('product', 'bought_by', 'user'): SAGEConv((-1, -1), output_dim),\n",
        "        }, aggr='mean')\n",
        "\n",
        "    # The forward function should be indented to be part of the HeteroGNN class\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        print(\"Input x_dict Keys:\", x_dict.keys())\n",
        "        print(\"Input Edge Index Dict Keys:\", edge_index_dict.keys())\n",
        "\n",
        "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
        "        # print(\"After conv1:\", {key: x.shape for key, x in x_dict.items()})\n",
        "\n",
        "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
        "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
        "        print(\"After conv2:\", {key: x.shape for key, x in x_dict.items()})\n",
        "\n",
        "        return x_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31161904-b1a6-4a36-9f2d-1b52a594f85f",
      "metadata": {
        "id": "31161904-b1a6-4a36-9f2d-1b52a594f85f"
      },
      "source": [
        "## 9. Initialize Model and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3b5a8a0f-34c5-43d8-b82f-80270082d24e",
      "metadata": {
        "id": "3b5a8a0f-34c5-43d8-b82f-80270082d24e"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 64\n",
        "output_dim = 32\n",
        "model = HeteroGNN(hidden_dim, output_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4784b4a-9e3c-4955-8718-db9c19b232e2",
      "metadata": {
        "id": "d4784b4a-9e3c-4955-8718-db9c19b232e2"
      },
      "source": [
        "## 10. Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "81a1269a-5429-4772-beb0-7d5c0b3a19c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81a1269a-5429-4772-beb0-7d5c0b3a19c4",
        "outputId": "94562dc6-ca22-4a67-de9c-8271e7a4476c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 1: New best validation loss: 414.2592\n",
            "Epoch 1, Train Loss: 330.5005, Validation Loss: 414.2592\n",
            "Epoch 1, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 2: New best validation loss: 271.7820\n",
            "Epoch 2, Train Loss: 312.3739, Validation Loss: 271.7820\n",
            "Epoch 2, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 3, Train Loss: 398.1452, Validation Loss: 527.3440\n",
            "Epoch 3, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 4: New best validation loss: 244.7380\n",
            "Epoch 4, Train Loss: 254.6143, Validation Loss: 244.7380\n",
            "Epoch 4, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 5, Train Loss: 442.7779, Validation Loss: 626.6710\n",
            "Epoch 5, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 6, Train Loss: 344.1589, Validation Loss: 328.2508\n",
            "Epoch 6, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 7, Train Loss: 309.9890, Validation Loss: 293.1843\n",
            "Epoch 7, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Epoch 8, Train Loss: 408.2746, Validation Loss: 401.8752\n",
            "Epoch 8, Validation Precision@5: 0.0000, Recall@5: 0.0000, F1@5: 0.0000\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Input x_dict Keys: dict_keys(['user', 'product'])\n",
            "Input Edge Index Dict Keys: dict_keys([('user', 'bought', 'product'), ('product', 'bought_by', 'user')])\n",
            "After conv2: {'product': torch.Size([39123, 32]), 'user': torch.Size([131209, 32])}\n",
            "Early stopping at epoch 9. Best validation loss: 244.7380\n"
          ]
        }
      ],
      "source": [
        "def evaluate_recommendations(data, model, k=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x_dict, data.edge_index_dict)\n",
        "        user_emb = out['user']\n",
        "        product_emb = out['product']\n",
        "        precision_list, recall_list, f1_list = [], [], []\n",
        "        for user_idx in range(user_emb.size(0)):\n",
        "            scores = torch.matmul(user_emb[user_idx], product_emb.T)\n",
        "            top_k_products = scores.topk(k).indices\n",
        "            ground_truth = data['user', 'bought', 'product'].edge_index[1][\n",
        "                data['user', 'bought', 'product'].edge_index[0] == user_idx\n",
        "            ]\n",
        "            top_k_set = set(top_k_products.tolist())\n",
        "            ground_truth_set = set(ground_truth.tolist())\n",
        "            intersection = top_k_set & ground_truth_set\n",
        "            precision = len(intersection) / k\n",
        "            recall = len(intersection) / len(ground_truth_set) if len(ground_truth_set) > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1)\n",
        "        avg_precision = sum(precision_list) / len(precision_list)\n",
        "        avg_recall = sum(recall_list) / len(recall_list)\n",
        "        avg_f1 = sum(f1_list) / len(f1_list)\n",
        "        return avg_precision, avg_recall, avg_f1\n",
        "\n",
        "for epoch in range(50):\n",
        "    # Training Phase\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(train_data.x_dict, train_data.edge_index_dict)\n",
        "    user_emb = out['user']\n",
        "    product_emb = out['product']\n",
        "    edge_emb = torch.cat([\n",
        "      user_emb[train_data['user', 'bought', 'product'].edge_index[0]],\n",
        "      product_emb[train_data['user', 'bought', 'product'].edge_index[1]]\n",
        "    ], dim=1)\n",
        "\n",
        "    # Apply a linear layer to reduce the dimensionality of edge_emb to match edge_attr\n",
        "    linear_layer = torch.nn.Linear(edge_emb.shape[1], train_data['user', 'bought', 'product'].edge_attr.shape[1]) #added\n",
        "    edge_emb = linear_layer(edge_emb) #added\n",
        "\n",
        "    train_loss = F.mse_loss(edge_emb, train_data['user', 'bought', 'product'].edge_attr)\n",
        "    train_loss.backward() # Fixed indentation: Aligned with train_loss calculation\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out_val = model(val_data.x_dict, val_data.edge_index_dict)\n",
        "        user_emb_val = out_val['user']\n",
        "        product_emb_val = out_val['product']\n",
        "        edge_emb_val = torch.cat([\n",
        "            user_emb_val[val_data['user', 'bought', 'product'].edge_index[0]],\n",
        "            product_emb_val[val_data['user', 'bought', 'product'].edge_index[1]]\n",
        "        ], dim=1)\n",
        "\n",
        "        # Apply the same linear layer used in training to reduce dimensionality\n",
        "        edge_emb_val = linear_layer(edge_emb_val)\n",
        "\n",
        "        val_loss = F.mse_loss(edge_emb_val, val_data['user', 'bought', 'product'].edge_attr)\n",
        "\n",
        "    # Evaluate Precision, Recall, and F1 on Validation Data\n",
        "    precision, recall, f1 = evaluate_recommendations(val_data, model, k=5)\n",
        "\n",
        "    # Early Stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        print(f\"Epoch {epoch + 1}: New best validation loss: {val_loss.item():.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch + 1}. Best validation loss: {best_val_loss:.4f}\")\n",
        "        break\n",
        "\n",
        "    # Print losses and validation metrics\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\")\n",
        "    print(f\"Epoch {epoch + 1}, Validation Precision@5: {precision:.4f}, Recall@5: {recall:.4f}, F1@5: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check edge index shape\n",
        "print(\"Edge Index Shape:\", train_data['user', 'bought', 'product'].edge_index.shape)\n",
        "\n",
        "# Check edge attribute shape\n",
        "print(\"Edge Attribute Shape:\", train_data['user', 'bought', 'product'].edge_attr.shape)\n",
        "\n",
        "# Optionally print some sample values to confirm the data\n",
        "print(\"Sample Edge Index:\", train_data['user', 'bought', 'product'].edge_index[:, :5])\n",
        "print(\"Sample Edge Attributes:\", train_data['user', 'bought', 'product'].edge_attr[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1toqa3EGusu",
        "outputId": "6dd8736e-2281-4f8e-f5f3-32d05fc7ab10"
      },
      "id": "E1toqa3EGusu",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index Shape: torch.Size([2, 969231])\n",
            "Edge Attribute Shape: torch.Size([969231, 2])\n",
            "Sample Edge Index: tensor([[ 45661,  46473,  18420, 102887,  98225],\n",
            "        [   123,   1243,   1372,   9530,    470]])\n",
            "Sample Edge Attributes: tensor([[ 7.,  8.],\n",
            "        [ 5., 30.],\n",
            "        [26., 30.],\n",
            "        [ 1., 20.],\n",
            "        [ 7.,  5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e34ca7-0947-4dd7-8711-7789eb53df48",
      "metadata": {
        "id": "f2e34ca7-0947-4dd7-8711-7789eb53df48"
      },
      "source": [
        "## 11. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba46aee-b351-494f-8543-8f40c761e633",
      "metadata": {
        "id": "fba46aee-b351-494f-8543-8f40c761e633"
      },
      "outputs": [],
      "source": [
        "def evaluate_recommendations(data, model, k=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x_dict, data.edge_index_dict)\n",
        "        user_emb = out['user']\n",
        "        product_emb = out['product']\n",
        "        precision_list, recall_list, f1_list = [], [], []\n",
        "        for user_idx in range(user_emb.size(0)):\n",
        "            scores = torch.matmul(user_emb[user_idx], product_emb.T)\n",
        "            top_k_products = scores.topk(k).indices\n",
        "            ground_truth = data['user', 'bought', 'product'].edge_index[1][\n",
        "                data['user', 'bought', 'product'].edge_index[0] == user_idx\n",
        "            ]\n",
        "            top_k_set = set(top_k_products.tolist())\n",
        "            ground_truth_set = set(ground_truth.tolist())\n",
        "            intersection = top_k_set & ground_truth_set\n",
        "            precision = len(intersection) / k\n",
        "            recall = len(intersection) / len(ground_truth_set) if len(ground_truth_set) > 0 else 0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1)\n",
        "        avg_precision = sum(precision_list) / len(precision_list)\n",
        "        avg_recall = sum(recall_list) / len(recall_list)\n",
        "        avg_f1 = sum(f1_list) / len(f1_list)\n",
        "        print(f\"Precision@{k}: {avg_precision:.4f}, Recall@{k}: {avg_recall:.4f}, F1@{k}: {avg_f1:.4f}\")\n",
        "        return avg_precision, avg_recall, avg_f1\n",
        "\n",
        "# Evaluate on test data\n",
        "precision, recall, f1 = evaluate_recommendations(test_data, model, k=5)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}